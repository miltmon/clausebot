# ClauseBot CI/CD Workflows

**Purpose:** Automated validation and monitoring for ClauseBot RAG deployment

---

## Workflows Overview

| Workflow | Trigger | Purpose | Runtime |
|----------|---------|---------|---------|
| `post-deploy-smoke.yml` | Push to `main` | Quick sanity checks post-deployment | ~2 min |
| `golden-validation.yml` | Nightly (cron) + manual | RAG retrieval accuracy validation | ~5 min |

---

## 1. Post-Deploy Smoke Tests

**File:** `post-deploy-smoke.yml`

**Purpose:** Immediate validation that core functionality works after deployment

**Triggers:**
- Push to `main` branch
- Can be manually triggered via GitHub Actions UI

**What it tests:**
- `/health` endpoint (API up)
- `/api/quiz/baseline/random` (existing functionality intact)
- `/v1/chat/compliance/health` (RAG endpoint health)
- Sample RAG query (if `RAG_ENABLED=true`)
- Optional: Supabase clause count

**Success Criteria:**
- All endpoints return 2xx status
- JSON responses well-formed
- Latency <5s per check

**On Failure:**
- Workflow fails (red X on commit)
- Logs uploaded as artifact
- Optional Slack notification sent
- **Action:** Review logs, follow rollback playbook if needed

**Secrets Required:**
- `API_BASE` (optional, defaults to production URL)
- `SUPABASE_URL` (optional, for DB checks)
- `SUPABASE_SERVICE_ROLE_KEY` (optional)
- `RENDER_API_KEY` + `RENDER_SERVICE_ID` (optional, for deploy polling)
- `SLACK_WEBHOOK` (optional, for notifications)

---

## 2. Golden Dataset Validation

**File:** `golden-validation.yml`

**Purpose:** Continuous monitoring of RAG retrieval accuracy against curated test queries

**Triggers:**
- **Nightly:** 3:00 AM UTC (cron: `0 3 * * *`)
- **Manual:** Via GitHub Actions workflow_dispatch

**What it tests:**
- 30 golden queries against production `/v1/chat/compliance`
- Checks if expected clauses appear in top-K results
- Validates similarity scores meet thresholds
- Measures latency per query

**Success Criteria:**
- Pass rate ≥90% (configurable in workflow)
- Average latency <4s
- No 5xx errors from API

**On Failure:**
- Workflow fails
- JSON + CSV reports uploaded as artifacts
- Team triage required (see `GOLDEN_FAILURE_CHECKLIST.md`)
- Optional: Auto-creates GitHub issue (see `AUTO_ISSUE_ENHANCEMENT.md`)

**Secrets Required:**
- `API_BASE`
- `OPENAI_API_KEY` (if needed by validator)
- `SUPABASE_URL` (optional)
- `SUPABASE_SERVICE_ROLE_KEY` (optional)

---

## Setting Up Secrets

### Required Secrets

Add these in: **GitHub Repo → Settings → Secrets and variables → Actions**

```
API_BASE=https://clausebot-api.onrender.com
SUPABASE_URL=https://hqhugh...supabase.co
SUPABASE_SERVICE_ROLE_KEY=service_role_...
```

### Optional Secrets (Recommended)

```
RENDER_API_KEY=rnd_...           # For deploy polling
RENDER_SERVICE_ID=srv-...        # Your Render service ID
SLACK_WEBHOOK=https://hooks.slack.com/services/...
OPENAI_API_KEY=sk-...            # If golden-validate needs it
```

**Security:**
- Rotate `SUPABASE_SERVICE_ROLE_KEY` quarterly
- Never commit secrets to repo
- Use GitHub Secrets (encrypted at rest)

---

## Interpreting Results

### ✅ Green Check (Success)

**Smoke Tests:**
- All endpoints responded correctly
- No action required

**Golden Validation:**
- Pass rate ≥90%
- RAG retrieval quality acceptable
- No action required

### ❌ Red X (Failure)

**Smoke Tests Failed:**
1. Click workflow run → Download `smoke-test-log` artifact
2. Review errors (connection timeout? 5xx? wrong response?)
3. Check Render logs for backend errors
4. Follow `ops/rollback-playbook.md` if critical

**Golden Validation Failed:**
1. Click workflow run → Download `golden-validation-reports` artifact
2. Open `golden-report-*.csv` in Excel/Google Sheets
3. Identify failed tests (check `reason` column)
4. Follow `.github/workflows/GOLDEN_FAILURE_CHECKLIST.md`
5. Classify failure type (retrieval, infra, data quality)
6. Apply remediation or escalate

---

## Workflow Artifacts

### What are artifacts?

Artifacts are files generated by workflows and stored for download/review.

**Retention:** 90 days (GitHub default)

### Available Artifacts

| Artifact | Source Workflow | Contents |
|----------|----------------|----------|
| `smoke-test-log` | post-deploy-smoke | Full smoke script output |
| `golden-validation-reports` | golden-validation | JSON + CSV reports |

### Downloading Artifacts

1. Go to workflow run (GitHub Actions tab)
2. Scroll to "Artifacts" section
3. Click artifact name to download ZIP
4. Extract and review

---

## Troubleshooting

### Workflow Won't Trigger

**Symptoms:** Push to `main` but no workflow run appears

**Check:**
- Workflow file in `.github/workflows/` directory
- YAML syntax valid (paste into [yamllint.com](http://yamllint.com))
- Branch name matches trigger (check for `master` vs `main`)

**Fix:** Re-push or manually trigger via Actions UI

### Secrets Not Working

**Symptoms:** Workflow fails with "SUPABASE_URL not set" or similar

**Check:**
- Secret name spelling (case-sensitive)
- Secret created in correct repo (not organization)
- Workflow references secret correctly: `${{ secrets.SECRET_NAME }}`

**Fix:** Verify in Settings → Secrets, re-add if needed

### Timeout Errors

**Symptoms:** Workflow times out after 6+ minutes

**Cause:** API slow or down, Render cold start, network issue

**Fix:**
- Check Render service status
- Increase `--timeout` in smoke script or golden-validate
- Review API logs for slow queries

### False Positives (Golden Validation)

**Symptoms:** Tests fail but manual review shows correct results

**Cause:** Similarity threshold too strict, chunking issues, embedding drift

**Fix:**
- Lower `min_similarity` in `golden.json` for specific tests
- Re-ingest clauses with improved chunking
- Review and update expected_clauses in golden.json

---

## Best Practices

### DO:
✅ Review failed workflow runs within 24 hours  
✅ Keep golden dataset small and curated (20-50 tests)  
✅ Update golden.json when standards change  
✅ Download and archive critical failure artifacts  
✅ Use manual triggers for ad-hoc validation  

### DON'T:
❌ Ignore persistent failures (fix or disable workflow)  
❌ Commit secrets to workflows  
❌ Set pass-rate too low (<80% is meaningless)  
❌ Run heavy tests on every push (use nightly instead)  
❌ Skip artifact review when failures occur  

---

## Maintenance Cadence

**Weekly:**
- Review golden validation results (even on success)
- Check for slow tests (latency outliers)
- Verify artifact retention policy

**Monthly:**
- Update golden dataset with new quiz questions
- Review and archive old artifacts
- Check secret expiration dates

**Quarterly:**
- Rotate `SUPABASE_SERVICE_ROLE_KEY`
- Review workflow efficiency (runtime, cost)
- Update YAML syntax for new GitHub Actions features

---

## Extending Workflows

### Adding New Smoke Checks

Edit `ops/smoke-script.sh`:
```bash
# Add new check
echo "Checking new endpoint..."
curl -sS -f "$API_BASE/new/endpoint" || EXIT_CODE=1
```

Commit and push — workflow automatically uses updated script.

### Adding New Golden Tests

Edit `ops/golden_dataset/golden.json`:
```json
{
  "id": "gd-031",
  "query": "New compliance question?",
  "expected_clauses": ["x.y.z"],
  "min_similarity": 0.70
}
```

Push to main — nightly run will include new test.

### Creating New Workflows

1. Copy existing workflow as template
2. Update name, triggers, and steps
3. Test in feature branch first
4. Document in this README
5. Add to TEAM_RESPONSIBILITIES.md

---

## Related Documentation

- **Deployment Runbook:** `../backend/DEPLOYMENT_RUNBOOK_CURSOR.md`
- **Failure Checklist:** `GOLDEN_FAILURE_CHECKLIST.md`
- **Rollback Playbook:** `../ops/rollback-playbook.md`
- **Team Responsibilities:** `../backend/TEAM_RESPONSIBILITIES.md`
- **Auto-Issue Setup:** `AUTO_ISSUE_ENHANCEMENT.md`

---

## Contact & Escalation

**Workflow Issues:**
- Platform/SRE: [Contact from TEAM_RESPONSIBILITIES.md]

**Golden Validation Failures:**
- RAG Team: [Contact from TEAM_RESPONSIBILITIES.md]
- QA Lead: [Contact from TEAM_RESPONSIBILITIES.md]

**Emergency (Production Down):**
- On-call SRE: [PagerDuty link]

---

**Last Updated:** 2025-11-02  
**Maintained By:** Platform Team  
**Review Frequency:** Monthly

